resources:
  - deployment.yaml
  - service.yaml
  - route.yaml
  - pvc.yaml

secretGenerator:
  - name: inference-server-config
    literals:
      - DISABLE_TELEMETRY=true
      - GENERIC_OPEN_AI_API_KEY=
      - GENERIC_OPEN_AI_BASE_PATH=http://vllm.vllm-cpu.svc.cluster.local:8000/v1
      - GENERIC_OPEN_AI_MAX_TOKENS=4096
      - GENERIC_OPEN_AI_MODEL_PREF=local-llm
      - LLM_PROVIDER=generic-openai
      - GENERIC_OPEN_AI_MODEL_TOKEN_LIMIT=32768
      - VECTOR_DB=lancedb
      - EMBEDDING_ENGINE=native
    options:
      disableNameSuffixHash: false
